{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c93849-b8fb-4fc7-ac95-6c82d8afb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "import json\n",
    "import boto3\n",
    "import s3fs\n",
    "import shutil\n",
    "from typing import Any, Dict, Generic, Iterable, List, Optional, TypeVar, Union, cast\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box, mapping, Polygon, LinearRing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pystac\n",
    "from pystac import Catalog, get_stac_version, Collection, Item, STACObject, CatalogType, Link\n",
    "from pystac.stac_io import DefaultStacIO, StacIO\n",
    "from pystac.extensions.projection import AssetProjectionExtension, ProjectionExtension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e174b5f-98f7-4e16-86cc-4ce11cd2b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this block once we are in GDAL >= 3.5\n",
    "\n",
    "awsdir = pathlib.Path(\"~/.aws\").expanduser()\n",
    "awsdir.mkdir(exist_ok=True)\n",
    "awscred = awsdir / \"credentials\"\n",
    "\n",
    "session = boto3.session.Session()\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "#Credentials are refreshable, so accessing your access key / secret key\n",
    "#separately can lead to a race condition. Use this to get an actual matched\n",
    "#set. \n",
    "\n",
    "outstring = f\"\"\"\n",
    "[default]\n",
    "aws_access_key_id={credentials.access_key}\n",
    "aws_secret_access_key={credentials.secret_key}\n",
    "aws_session_token={credentials.token}\n",
    "\"\"\"\n",
    "with awscred.open(mode='w') as f:\n",
    "    f.write(outstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51737b8-69d8-4840-8a3b-4ff7035ab351",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bucket = \"dh-shift-curated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4c667-c173-4d40-928f-faf2705c9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve STAC catalog\n",
    "catalog_url = \"efs/SBG-SHIFT-STAC/catalog.json\"\n",
    "collection_url = \"/efs/SBG-SHIFT-STAC/collection.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73dc06-2984-4851-87a2-ae1704a25eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Catalog.from_file(catalog_url)\n",
    "catalog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b480d-f56c-459b-a071-6f2d13cefe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As new data becomes available for AVIRIS-NG, add to catalog\n",
    "\n",
    "# Read in data from S3 bucket\n",
    "def get_zarrs(Bucket, dataset_date):\n",
    "    s3 = boto3.client('s3')\n",
    "    Prefix = f'aviris/{dataset_date}'\n",
    "    kwargs = {'Bucket': Bucket, 'Prefix': Prefix}\n",
    "    substring = '100-100-100.zarr'\n",
    "    links = []\n",
    "    while True:\n",
    "        objects = s3.list_objects_v2(**kwargs)\n",
    "        for obj in objects['Contents']:\n",
    "            if substring in obj['Key']:\n",
    "                key = obj['Key']\n",
    "                url = key[:key.index(substring)+ len(substring)]\n",
    "                zarr = url.replace(f\"aviris/{dataset_date}/\", \"\")\n",
    "                links.append(str(zarr))\n",
    "            \n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = objects['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break\n",
    "     \n",
    "    data_set = set(links)\n",
    "    data = list(data_set)\n",
    "    #print(data) # see results\n",
    "    print(\"Data retrieved\")\n",
    "    return data\n",
    "\n",
    "def create_items_add_assets(Bucket, dataset_date, zarr):\n",
    "    Prefix = f\"aviris/{dataset_date}/{zarr}\"\n",
    "    s3_key = os.path.join(Bucket, Prefix)\n",
    "    \n",
    "    # Open flight path zarr\n",
    "    s3 = s3fs.S3FileSystem(anon=False, client_kwargs=dict(region_name='us-west-2'))\n",
    "    s3_path = f\"s3://{s3_key}\"\n",
    "    store = s3fs.S3Map(root=s3_path, s3=s3, check=False)\n",
    "    ds = xr.open_zarr(store=store, decode_coords=\"all\", consolidated=True)\n",
    "    print(\"Zarr read done!\")\n",
    "    \n",
    "    # Set dimensions and coordinates\n",
    "    ds = ds.rio.set_spatial_dims(x_dim='x', y_dim='y')\n",
    "    ds = ds.set_coords(('Easting', 'Northing'))\n",
    "\n",
    "     # Calculate extent, bbox, and footprint using Easting & Northing\n",
    "    ul = ds.isel(x=0, y=0)  # Upper left corner\n",
    "    ur = ds.isel(x=-1, y=0) # Upper right corner\n",
    "    ll = ds.isel(x=0, y=-1) # Lower left corner\n",
    "    lr = ds.isel(x=-1, y=-1) # Lower right corner\n",
    "\n",
    "    ul2 = (np.min(ul.Easting.values), np.max(ul.Northing.values))\n",
    "    ur2 = (np.max(ur.Easting.values), np.max(ur.Northing.values))\n",
    "    ll2 = (np.min(ll.Easting.values), np.min(ll.Northing.values))\n",
    "    lr2 = (np.max(lr.Easting.values), np.min(lr.Northing.values))\n",
    "    \n",
    "    extent = Polygon([ul2, ll2, lr2, ur2])\n",
    "    footprint = mapping(extent)\n",
    "\n",
    "    # save flight outline as GeoJSON and upload to s3\n",
    "    substring = '_100-100-100.zarr'\n",
    "    item_name = zarr[:zarr.index(substring)]\n",
    "\n",
    "    gpd.GeoDataFrame({\"geometry\": extent}, index=[0]).to_file(f\"{item_name}_flight_outline.geojson\", driver='GeoJSON')\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    kwargs = {'Bucket': Bucket, 'Key': f\"aviris/{dataset_date}/{item_name}_flight_outline.geojson\"}\n",
    "    s3.put_object(**kwargs)\n",
    "    \n",
    "    bbox = extent.bounds\n",
    "    \n",
    "    # create datetime object from date string\n",
    "    dt = datetime.strptime(dataset_date, f\"%Y%m%d\")\n",
    "    \n",
    "    item_url = \"/efs/SBG-SHIFT-STAC/AVIRIS-NG/{item_name}.json\"\n",
    "\n",
    "    # item should be flight line\n",
    "    item = pystac.Item(id=f\"{item_name}\",\n",
    "                    geometry=footprint, \n",
    "                    bbox=bbox, \n",
    "                    datetime=dt,\n",
    "                    href=item_url,\n",
    "                    stac_extensions=['https://stac-extensions.github.io/projection/v1.0.0/schema.json'],\n",
    "                    properties={},\n",
    "                    collection = 'AVIRIS-NG'\n",
    "                      )\n",
    "    # add instrument metadata\n",
    "    item.common_metadata.instruments = ['AVIRIS-NG']\n",
    "\n",
    "    # add projection extension to item\n",
    "    proj_ext = ProjectionExtension.ext(item, add_if_missing = True)\n",
    "    proj_ext.epsg = 32610\n",
    "    print(\"Item created!\")\n",
    "    \n",
    "    # Add dataset asset\n",
    "    print(\"Adding assets\")\n",
    "    item.add_asset(\n",
    "        key=\"dataset\",\n",
    "        asset=pystac.Asset(\n",
    "            href= f\"https://dh-shift-curated.s3.us-west-2.amazonaws.com/aviris/{dataset_date}/{zarr}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # extend the asset with projection extension\n",
    "    asset_ext = AssetProjectionExtension.ext(item.assets[\"dataset\"])\n",
    "    asset_ext.epsg = 32610\n",
    "    asset_ext.bbox = bbox\n",
    "    asset_ext.geometry = footprint\n",
    "\n",
    "    # Add flight outline GeoJSON asset\n",
    "    item.add_asset(\n",
    "        key=\"Flight Outline\",\n",
    "        asset=pystac.Asset(\n",
    "            href= f\"https://dh-shift-curated.s3.us-west-2.amazonaws.com/aviris/{dataset_date}/{item_name}_flight_outline.geojson\",\n",
    "            media_type=pystac.MediaType.GEOJSON\n",
    "            )\n",
    "    )\n",
    "    print(\"Assets added!\")\n",
    "    zarrs_to_items[item_name] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda2529-4da1-4524-aba5-373f6fb0c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional dates after 20220412 to be added later\n",
    "dates = ['20220420', '20220429', '20220503' # plus any other dates\n",
    "        ]\n",
    "\n",
    "zarrs_to_items = {}\n",
    "\n",
    "for dataset_date in dates:\n",
    "    data = get_zarrs(Bucket, dataset_date)\n",
    "    \n",
    "    for zarr in data:\n",
    "        substring = '_100-100-100.zarr'\n",
    "        item_name = zarr[:zarr.index(substring)]\n",
    "        print(f\"Starting {item_name}\")\n",
    "        \n",
    "        # create STAC item and add assets, including Zarr dataset\n",
    "        create_items_add_assets(Bucket, dataset_date, zarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea523d-9200-49a9-ac1f-525e41a54505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add items to collection\n",
    "collection.add_items(zarrs_to_items.values())\n",
    "collection.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c77613-1129-4826-84db-f3170f3e7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add STAC Collection to STAC catalog\n",
    "catalog.add_child(collection)\n",
    "catalog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925f719-2d0f-4a4e-a4e1-7b635bbae812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add labels and of GeoTIFFs are created:\n",
    "# https://pystac.readthedocs.io/en/stable/tutorials/pystac-spacenet-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e0f37-ed5d-4f72-8ee0-0b58b17f7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new modified catalog to efs\n",
    "catalog.normalize_hrefs(catalog_url)\n",
    "catalog.save(catalog_type=CatalogType.SELF_CONTAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f8487-3f35-4296-9ba5-72277fd2ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open newly-modified catalog\n",
    "copycat = Catalog.from_file(catalog_url)\n",
    "\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
